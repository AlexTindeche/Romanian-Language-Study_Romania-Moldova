{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "romanian_texts = {}\n",
    "moldavian_texts = {}\n",
    "\n",
    "conn = sqlite3.connect('news.db')\n",
    "c = conn.cursor()\n",
    "\n",
    "c.execute('SELECT * FROM romania')\n",
    "rows = c.fetchall()\n",
    "for row in rows:\n",
    "    if row[4] not in romanian_texts:\n",
    "        romanian_texts[row[4]] = []\n",
    "    romanian_texts[row[4]].append(row[5])\n",
    "    \n",
    "c.execute('SELECT * FROM moldova WHERE newspaper != \"zugo\"')\n",
    "rows = c.fetchall()\n",
    "for row in rows:\n",
    "    if row[4] not in moldavian_texts:\n",
    "        moldavian_texts[row[4]] = []\n",
    "    moldavian_texts[row[4]].append(row[5])\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_texts = {\"romana\": '', \"moldova\": ''}\n",
    "\n",
    "for key in romanian_texts:\n",
    "    all_texts[\"romana\"] += ' '.join(romanian_texts[key])\n",
    "\n",
    "for key in moldavian_texts:\n",
    "    all_texts[\"moldova\"] += ' '.join(moldavian_texts[key])\n",
    "    \n",
    "all_texts['romana'] = all_texts['romana'][:1000000]\n",
    "all_texts['moldova'] = all_texts['moldova'][:1000000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download ro_core_news_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('ro_core_news_md')\n",
    "\n",
    "# Split text into 4-grams using spacy\n",
    "def split_text(text):\n",
    "    doc = nlp(text)\n",
    "    # doc = [token for token in doc if not token.is_punct]\n",
    "    return [doc[i:i+5] for i in range(len(doc)-4)]\n",
    "\n",
    "all_grams = {'romana': split_text(all_texts['romana']), 'moldova': split_text(all_texts['moldova'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the frequency of each 4-gram\n",
    "from collections import Counter\n",
    "\n",
    "all_grams_freq3 = {\"romana\": {}, \"moldova\": {}}\n",
    "\n",
    "# Get 4 grams and add the 5th word with the frequency\n",
    "\n",
    "for key in all_grams:\n",
    "    for gram in all_grams[key]:\n",
    "        gram4 = ''\n",
    "        for i in range(4):\n",
    "            gram4 += gram[i].text + ' '\n",
    "        gram4 = gram4[:-1]\n",
    "        if gram4 not in all_grams_freq3[key]:\n",
    "            all_grams_freq3[key][gram4] = Counter()\n",
    "        all_grams_freq3[key][gram4][gram[4].text] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text generat automat Romania: PENTRU MAI MULTE REGIUNI DIN ROMÂNIA ) Un ciclon polar lovește România Așa cum spuneam , testul de astăzi are o dificultate ridicată și necesită ceva mai multă atenție și concentrare .\n",
      "Text generat automat Moldova: Aici , Danemarca si Germania vor avea din start cate patru puncte , Romania si Polonia vor avea cate doua , iar Japonia si Serbia - nici cate unul .\n"
     ]
    }
   ],
   "source": [
    "# Get a random 4-gram\n",
    "import random\n",
    "\n",
    "def get_random_4gram(language):\n",
    "    return random.choice([x for x in all_grams_freq3[language].keys() if (x[0].isupper() or x[0] == '\"' or x[0] == \"'\" or x[0] == '(') and '.' not in x and '?' not in x and '!' not in x])\n",
    "\n",
    "# Get the most common 4-gram with 3 given words\n",
    "def get_most_common_4gram(words, language):\n",
    "    try:\n",
    "        rv = all_grams_freq3[language][words].most_common(1)[0][0]   \n",
    "        # print(1)\n",
    "    except:\n",
    "        rv = '.'\n",
    "        \n",
    "    return rv\n",
    "\n",
    "# Generate a new text\n",
    "def generate_text(language):\n",
    "    text = get_random_4gram(language)\n",
    "    text4 = [token for token in text.split(' ')]\n",
    "    # text = ' '.join([token for token in text]))\n",
    "    # print(all_grams_freq3[language][text].most_common(1))\n",
    "    # print(text)\n",
    "    for i in range(30):\n",
    "        next_4gram = get_most_common_4gram(' '.join(text4), language)\n",
    "        word = next_4gram.split(' ')[-1]\n",
    "        \n",
    "        text += ' ' + word\n",
    "        text4 = text4[1:] + [word]\n",
    "        \n",
    "        if word in ['.', '?', '!']:\n",
    "            break\n",
    "        \n",
    "    return text\n",
    "\n",
    "txt_ro = generate_text('romana')\n",
    "txt_md = generate_text('moldova')\n",
    "\n",
    "print(f\"Text generat automat Romania: {txt_ro}\")\n",
    "print(f\"Text generat automat Moldova: {txt_md}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
