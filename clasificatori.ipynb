{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sqlite3\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from stop_words import get_stop_words\n",
    "import shap\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Romanian categories: 16\n",
      "Moldavian categories: 14\n"
     ]
    }
   ],
   "source": [
    "romanian_texts = {}\n",
    "moldavian_texts = {}\n",
    "\n",
    "conn = sqlite3.connect('news_diacritics_final.db')\n",
    "c = conn.cursor()\n",
    "\n",
    "c.execute('SELECT * FROM romania')\n",
    "rows = c.fetchall()\n",
    "for row in rows:\n",
    "    if row[4] not in romanian_texts:\n",
    "        romanian_texts[row[4]] = []\n",
    "    romanian_texts[row[4]].append(row[5].strip())\n",
    "    \n",
    "print('Romanian categories:', len(romanian_texts))\n",
    "\n",
    "c.execute('SELECT * FROM moldova')\n",
    "rows = c.fetchall()\n",
    "for row in rows:\n",
    "    text = ''\n",
    "    if len(row[5]) > 10000:\n",
    "        text = row[5][:10000]\n",
    "    else:\n",
    "        text = row[5]\n",
    "    if row[4] not in moldavian_texts:\n",
    "        moldavian_texts[row[4]] = []\n",
    "        \n",
    "    moldavian_texts[row[4]].append(text)\n",
    "\n",
    "print('Moldavian categories:', len(moldavian_texts))\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# De aici: https://en.wiktionary.org/wiki/Category:Romanian_prefixes\n",
    "romanian_prefixes = [\n",
    "    # A\n",
    "    \"agro\", \"alt\", \"ante\", \"anti\", \"aorto\", \"arhi\", \"astro\",\n",
    "\n",
    "    # B\n",
    "    \"balano\",\n",
    "\n",
    "    # C\n",
    "    \"cardio\", \"carpo\", \"cosmo\",\n",
    "\n",
    "    # D\n",
    "    \"demono\", \"des\", \"dez\",\n",
    "\n",
    "    # F\n",
    "    \"franco\",\n",
    "\n",
    "    # G\n",
    "    \"gastro\", \"germano\", \"greco\",\n",
    "\n",
    "    # H\n",
    "    \"hecto\", \"hiper\",\n",
    "\n",
    "    # I\n",
    "    \"în\",\n",
    "\n",
    "    # K\n",
    "    \"kilo\",\n",
    "\n",
    "    # L\n",
    "    \"lexico\",\n",
    "\n",
    "    # M\n",
    "    \"mili\", \"muzico\",\n",
    "\n",
    "    # N\n",
    "    \"nano\", \"ne\",\n",
    "\n",
    "    # O\n",
    "    \"ori\", \"ornito\",\n",
    "\n",
    "    # P\n",
    "    \"pneumo\", \"pre\", \"prea\", \"proto\", \"pseudo\", \"psiho\",\n",
    "\n",
    "    # R\n",
    "    \"răs\", \"re\", \"rino\", \"ruso\",\n",
    "\n",
    "    # S\n",
    "    \"stră\", \"sub\",\n",
    "\n",
    "    # T\n",
    "    \"tehno\", \"teo\", \"termo\",\n",
    "\n",
    "    # V\n",
    "    \"vice\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cativa\n"
     ]
    }
   ],
   "source": [
    "def replace_i_prefix(word, prefixes):\n",
    "  for prefix in prefixes:\n",
    "    try:\n",
    "      if word.lower().startswith(prefix) and len(word) > len(prefix) and word[len(prefix):][0] in [\"î\", \"Î\"]:\n",
    "        first_letter = word[len(prefix):][0]\n",
    "        first_letter = \"i\" if first_letter == \"î\" else (\"I\" if first_letter == \"Î\" else first_letter)\n",
    "        word = prefix + first_letter + word[len(prefix) + 1:]\n",
    "\n",
    "    except:\n",
    "      print(word)\n",
    "    \n",
    "  word = word.replace(\"î\", \"a\").replace(\"Î\", \"A\")\n",
    "\n",
    "  return word\n",
    "\n",
    "def no_diacritics(text, prefixes):\n",
    "\n",
    "  text = replace_i_prefix(text, prefixes)\n",
    "\n",
    "\n",
    "  text = text.replace(\"â\", \"i\")\n",
    "  text = text.replace(\"Â\", \"I\")\n",
    "  text = text.replace(\"ș\", \"s\")\n",
    "  text = text.replace(\"ş\", \"s\")\n",
    "  text = text.replace(\"Ș\", \"S\")\n",
    "  text = text.replace(\"Ş\", \"S\")\n",
    "  text = text.replace(\"ț\", \"t\")\n",
    "  text = text.replace(\"ţ\", \"t\")\n",
    "  text = text.replace(\"Ț\", \"T\")\n",
    "  text = text.replace(\"Ţ\", \"T\")\n",
    "\n",
    "  # If î is the first letter of the word, replace it with i\n",
    "  if text.startswith(\"î\"):\n",
    "    text = text.replace(\"î\", \"i\")\n",
    "  if text.startswith(\"Î\"):\n",
    "    text = text.replace(\"Î\", \"I\")\n",
    "  # If the last letter of the word is î, replace it with i\n",
    "  if text.endswith(\"î\"):\n",
    "    text = text.replace(\"î\", \"i\")\n",
    "  if text.endswith(\"Î\"):\n",
    "    text = text.replace(\"Î\", \"I\")\n",
    "  # Else replace î with a\n",
    "  if \"î\" in text:\n",
    "    text = text.replace(\"î\", \"a\")     \n",
    "  # text = text.replace(\"î\", \"i\")\n",
    "  # text = text.replace(\"Î\", \"I\")\n",
    "  text = text.replace(\"ă\", \"a\")\n",
    "  text = text.replace(\"Ă\", \"A\")\n",
    "\n",
    "  return text\n",
    "\n",
    "\n",
    "# for key in moldavian_texts:\n",
    "#     for i in range(len(moldavian_texts[key])):\n",
    "#         moldavian_texts[key][i] = no_diacritics(moldavian_texts[key][i], romanian_prefixes)\n",
    "\n",
    "# for key in romanian_texts:\n",
    "#     for i in range(len(romanian_texts[key])):\n",
    "#         romanian_texts[key][i] = no_diacritics(romanian_texts[key][i], romanian_prefixes)\n",
    "\n",
    "# print(moldavian_texts[\"Sport\"][0])\n",
    "# print(romanian_texts['Stiri'][12])\n",
    "\n",
    "print(no_diacritics(\"cîțiva\", romanian_prefixes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "romanian=[\n",
    "    \"a\", \"abia\", \"acea\", \"aceasta\", \"această\", \"aceea\", \"aceeasi\", \"acei\",\n",
    "    \"aceia\", \"acel\", \"acela\", \"acelasi\", \"acele\", \"acelea\", \"acest\", \"acesta\",\n",
    "    \"aceste\", \"acestea\", \"acestei\", \"acestia\", \"acestui\", \"aceşti\", \"aceştia\",\n",
    "    \"acești\", \"aceștia\", \"acolo\", \"acord\", \"acum\", \"adica\", \"ai\", \"aia\",\n",
    "    \"aibă\", \"aici\", \"aiurea\", \"al\", \"ala\", \"alaturi\", \"ale\", \"alea\", \"alt\",\n",
    "    \"alta\", \"altceva\", \"altcineva\", \"alte\", \"altfel\", \"alti\", \"altii\", \"altul\",\n",
    "    \"alături\", \"am\", \"anume\", \"apoi\", \"ar\", \"are\", \"as\", \"asa\", \"asemenea\",\n",
    "    \"asta\", \"astazi\", \"astea\", \"astfel\", \"astăzi\", \"asupra\", \"atare\", \"atat\",\n",
    "    \"atata\", \"atatea\", \"atatia\", \"ati\", \"atit\", \"atita\", \"atitea\", \"atitia\",\n",
    "    \"atunci\", \"au\", \"avea\", \"avem\", \"aveţi\", \"aveți\", \"avut\", \"azi\", \"aş\",\n",
    "    \"aşadar\", \"aţi\", \"aș\", \"așadar\", \"ați\", \"b\", \"ba\", \"bine\", \"bucur\", \"bună\",\n",
    "    \"c\", \"ca\", \"cam\", \"cand\", \"capat\", \"care\", \"careia\", \"carora\", \"caruia\",\n",
    "    \"cat\", \"catre\", \"caut\", \"ce\", \"cea\", \"ceea\", \"cei\", \"ceilalti\", \"cel\",\n",
    "    \"cele\", \"celor\", \"ceva\", \"chiar\", \"ci\", \"cinci\", \"cind\", \"cine\", \"cineva\",\n",
    "    \"cit\", \"cita\", \"cite\", \"citeva\", \"citi\", \"câțiva\", \"conform\", \"contra\",\n",
    "    \"cu\", \"cui\", \"cum\", \"cumva\", \"curând\", \"curînd\", \"când\", \"cât\", \"câte\",\n",
    "    \"câtva\", \"câţi\", \"câți\", \"cînd\", \"cît\", \"cîte\", \"cîtva\", \"cîţi\", \"cîți\",\n",
    "    \"că\", \"căci\", \"cărei\", \"căror\", \"cărui\", \"către\", \"d\", \"da\", \"daca\",\n",
    "    \"dacă\", \"dar\", \"dat\", \"datorită\", \"dată\", \"dau\", \"de\", \"deasupra\", \"deci\",\n",
    "    \"decit\", \"degraba\", \"deja\", \"deoarece\", \"departe\", \"desi\", \"despre\",\n",
    "    \"deşi\", \"deși\", \"din\", \"dinaintea\", \"dintr\", \"dintr-\", \"dintre\", \"doar\",\n",
    "    \"doi\", \"doilea\", \"două\", \"drept\", \"dupa\", \"după\", \"dă\", \"e\", \"ea\", \"ei\",\n",
    "    \"el\", \"ele\", \"era\", \"eram\", \"este\", \"eu\", \"exact\", \"eşti\", \"ești\", \"f\",\n",
    "    \"face\", \"fara\", \"fata\", \"fel\", \"fi\", \"fie\", \"fiecare\", \"fii\", \"fim\", \"fiu\",\n",
    "    \"fiţi\", \"fiți\", \"foarte\", \"fost\", \"frumos\", \"fără\", \"g\", \"geaba\", \"graţie\",\n",
    "    \"grație\", \"h\", \"halbă\", \"i\", \"ia\", \"iar\", \"ieri\", \"ii\", \"il\", \"imi\", \"in\",\n",
    "    \"inainte\", \"inapoi\", \"inca\", \"incit\", \"insa\", \"intr\", \"intre\", \"isi\",\n",
    "    \"iti\", \"j\", \"k\", \"l\", \"la\", \"le\", \"li\", \"lor\", \"lui\", \"lângă\", \"lîngă\",\n",
    "    \"m\", \"ma\", \"mai\", \"mare\", \"mea\", \"mei\", \"mele\", \"mereu\", \"meu\", \"mi\",\n",
    "    \"mie\", \"mine\", \"mod\", \"mult\", \"multa\", \"multe\", \"multi\", \"multă\", \"mulţi\",\n",
    "    \"mulţumesc\", \"mulți\", \"mulțumesc\", \"mâine\", \"mîine\", \"mă\", \"n\", \"ne\",\n",
    "    \"nevoie\", \"ni\", \"nici\", \"niciodata\", \"nicăieri\", \"nimeni\", \"nimeri\",\n",
    "    \"nimic\", \"niste\", \"nişte\", \"niște\", \"noastre\", \"noastră\", \"noi\", \"noroc\",\n",
    "    \"nostri\", \"nostru\", \"nou\", \"noua\", \"nouă\", \"noştri\", \"noștri\", \"nu\",\n",
    "    \"numai\", \"o\", \"opt\", \"or\", \"ori\", \"oricare\", \"orice\", \"oricine\", \"oricum\",\n",
    "    \"oricând\", \"oricât\", \"oricînd\", \"oricît\", \"oriunde\", \"p\", \"pai\", \"parca\",\n",
    "    \"patra\", \"patru\", \"patrulea\", \"pe\", \"pentru\", \"peste\", \"pic\", \"pina\",\n",
    "    \"plus\", \"poate\", \"pot\", \"prea\", \"prima\", \"primul\", \"prin\", \"printr-\",\n",
    "    \"putini\", \"puţin\", \"puţina\", \"puţină\", \"puțin\", \"puțina\", \"puțină\", \"până\",\n",
    "    \"pînă\", \"r\", \"rog\", \"s\", \"sa\", \"sa-mi\", \"sa-ti\", \"sai\", \"sale\", \"sau\",\n",
    "    \"se\", \"si\", \"sint\", \"sintem\", \"spate\", \"spre\", \"sub\", \"sunt\", \"suntem\",\n",
    "    \"sunteţi\", \"sunteți\", \"sus\", \"sută\", \"sînt\", \"sîntem\", \"sînteţi\",\n",
    "    \"sînteți\", \"să\", \"săi\", \"său\", \"t\", \"ta\", \"tale\", \"te\", \"ti\", \"timp\",\n",
    "    \"tine\", \"toata\", \"toate\", \"toată\", \"tocmai\", \"tot\", \"toti\", \"totul\",\n",
    "    \"totusi\", \"totuşi\", \"totuși\", \"toţi\", \"toți\", \"trei\", \"treia\", \"treilea\",\n",
    "    \"tu\", \"tuturor\", \"tăi\", \"tău\", \"u\", \"ul\", \"ului\", \"un\", \"una\", \"unde\",\n",
    "    \"undeva\", \"unei\", \"uneia\", \"unele\", \"uneori\", \"unii\", \"unor\", \"unora\",\n",
    "    \"unu\", \"unui\", \"unuia\", \"unul\", \"v\", \"va\", \"vi\", \"voastre\", \"voastră\",\n",
    "    \"voi\", \"vom\", \"vor\", \"vostru\", \"vouă\", \"voştri\", \"voștri\", \"vreme\", \"vreo\",\n",
    "    \"vreun\", \"vă\", \"x\", \"z\", \"zece\", \"zero\", \"zi\", \"zice\", \"îi\", \"îl\", \"îmi\",\n",
    "    \"împotriva\", \"în\", \"înainte\", \"înaintea\", \"încotro\", \"încât\", \"încît\",\n",
    "    \"între\", \"întrucât\", \"întrucît\", \"îţi\", \"îți\", \"ăla\", \"ălea\", \"ăsta\",\n",
    "    \"ăstea\", \"ăştia\", \"ăștia\", \"şapte\", \"şase\", \"şi\", \"ştiu\", \"ţi\", \"ţie\",\n",
    "    \"șapte\", \"șase\", \"și\", \"știu\", \"ți\", \"ție\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get all the words from the stop words list and apply the same transformation\n",
    "stop_words = romanian\n",
    "for i in range(len(stop_words)):\n",
    "    stop_words[i] = no_diacritics(stop_words[i], romanian_prefixes)\n",
    "\n",
    "stop_words = list(set(stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'abia', 'acea', 'aceasta', 'aceea', 'aceeasi', 'acei', 'aceia', 'acel', 'acela', 'acelasi', 'acele', 'acelea', 'acest', 'acesta', 'aceste', 'acestea', 'acestei', 'acesti', 'acestia', 'acestui', 'acolo', 'acord', 'acum', 'adica', 'ai', 'aia', 'aiba', 'aici', 'aiurea', 'al', 'ala', 'alaturi', 'ale', 'alea', 'alt', 'alta', 'altceva', 'altcineva', 'alte', 'altfel', 'alti', 'altii', 'altul', 'am', 'ami', 'ampotriva', 'an', 'anainte', 'anaintea', 'ancat', 'ancit', 'ancotro', 'antre', 'antrucat', 'antrucit', 'anume', 'apoi', 'ar', 'are', 'as', 'asa', 'asadar', 'asemenea', 'asta', 'astazi', 'astea', 'astfel', 'astia', 'asupra', 'atare', 'atat', 'atata', 'atatea', 'atatia', 'ati', 'atit', 'atita', 'atitea', 'atitia', 'atunci', 'au', 'avea', 'avem', 'aveti', 'avut', 'azi', 'b', 'ba', 'bine', 'bucur', 'buna', 'c', 'ca', 'caci', 'cam', 'cand', 'capat', 'care', 'carei', 'careia', 'caror', 'carora', 'carui', 'caruia', 'cat', 'cate', 'cati', 'catre', 'catva', 'caut', 'ce', 'cea', 'ceea', 'cei', 'ceilalti', 'cel', 'cele', 'celor', 'ceva', 'chiar', 'ci', 'cinci', 'cind', 'cine', 'cineva', 'cit', 'cita', 'cite', 'citeva', 'citi', 'citiva', 'citva', 'conform', 'contra', 'cu', 'cui', 'cum', 'cumva', 'curand', 'curind', 'd', 'da', 'daca', 'dar', 'dat', 'data', 'datorita', 'dau', 'de', 'deasupra', 'deci', 'decit', 'degraba', 'deja', 'deoarece', 'departe', 'desi', 'despre', 'din', 'dinaintea', 'dintr', 'dintr-', 'dintre', 'doar', 'doi', 'doilea', 'doua', 'drept', 'dupa', 'e', 'ea', 'ei', 'el', 'ele', 'era', 'eram', 'este', 'esti', 'eu', 'exact', 'f', 'face', 'fara', 'fata', 'fel', 'fi', 'fie', 'fiecare', 'fii', 'fim', 'fiti', 'fiu', 'foarte', 'fost', 'frumos', 'g', 'geaba', 'gratie', 'h', 'halba', 'i', 'ia', 'iar', 'ieri', 'ii', 'il', 'imi', 'in', 'inainte', 'inapoi', 'inca', 'incit', 'insa', 'intr', 'intre', 'isi', 'iti', 'j', 'k', 'l', 'la', 'langa', 'le', 'li', 'linga', 'lor', 'lui', 'm', 'ma', 'mai', 'maine', 'mare', 'mea', 'mei', 'mele', 'mereu', 'meu', 'mi', 'mie', 'miine', 'mine', 'mod', 'mult', 'multa', 'multe', 'multi', 'multumesc', 'n', 'ne', 'nevoie', 'ni', 'nicaieri', 'nici', 'niciodata', 'nimeni', 'nimeri', 'nimic', 'niste', 'noastra', 'noastre', 'noi', 'noroc', 'nostri', 'nostru', 'nou', 'noua', 'nu', 'numai', 'o', 'opt', 'or', 'ori', 'oricand', 'oricare', 'oricat', 'orice', 'oricind', 'oricine', 'oricit', 'oricum', 'oriunde', 'p', 'pai', 'pana', 'parca', 'patra', 'patru', 'patrulea', 'pe', 'pentru', 'peste', 'pic', 'pina', 'plus', 'poate', 'pot', 'prea', 'prima', 'primul', 'prin', 'printr-', 'putin', 'putina', 'putini', 'r', 'rog', 's', 'sa', 'sa-mi', 'sa-ti', 'sai', 'sale', 'sant', 'santem', 'santeti', 'sapte', 'sase', 'sau', 'se', 'si', 'sint', 'sintem', 'spate', 'spre', 'stiu', 'sub', 'sunt', 'suntem', 'sunteti', 'sus', 'suta', 't', 'ta', 'tai', 'tale', 'tau', 'te', 'ti', 'tie', 'timp', 'tine', 'toata', 'toate', 'tocmai', 'tot', 'toti', 'totul', 'totusi', 'trei', 'treia', 'treilea', 'tu', 'tuturor', 'u', 'ul', 'ului', 'un', 'una', 'unde', 'undeva', 'unei', 'uneia', 'unele', 'uneori', 'unii', 'unor', 'unora', 'unu', 'unui', 'unuia', 'unul', 'v', 'va', 'vi', 'voastra', 'voastre', 'voi', 'vom', 'vor', 'vostri', 'vostru', 'voua', 'vreme', 'vreo', 'vreun', 'x', 'z', 'zece', 'zero', 'zi', 'zice']\n"
     ]
    }
   ],
   "source": [
    "print(sorted(stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25381\n",
      "25381\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "all_texts = {\"romana\": [], \"moldova\": []}\n",
    "\n",
    "for key in romanian_texts:\n",
    "    all_texts[\"romana\"].extend(romanian_texts[key])\n",
    "\n",
    "for key in moldavian_texts:\n",
    "    all_texts[\"moldova\"].extend(moldavian_texts[key])\n",
    "\n",
    "\n",
    "# Get the number of Romanian articles\n",
    "num_moldavian_articles = len(all_texts[\"moldova\"])\n",
    "\n",
    "# Randomly sample the same number of Moldavian articles\n",
    "all_texts[\"romana\"] = random.sample(all_texts[\"romana\"], num_moldavian_articles)\n",
    "\n",
    "print(len(all_texts[\"romana\"]))\n",
    "print(len(all_texts[\"moldova\"]))\n",
    "# X = []\n",
    "# y = []\n",
    "# for key in all_texts:\n",
    "#     X.extend(all_texts[key])\n",
    "#     y.extend([key]*len(all_texts[key]))\n",
    "    \n",
    "# X = np.array(X)\n",
    "# y = np.array(y)\n",
    "\n",
    "X_list = all_texts[\"romana\"] + all_texts[\"moldova\"]\n",
    "y_list = [\"romana\"]*num_moldavian_articles + [\"moldova\"]*num_moldavian_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [02:19<00:00, 46.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ministrul Economiei, Radu Oprea, a fost invitat la interviurile DC NEWS, emisiune moderată de Bogdan Chirieac, ce poate fi urmărită pe DC News, DC News TV și DC Business, dar și pe Youtube DC News și pe Facebook DC News. Radu Oprea a oferit informații de ultimă oră privind dezvoltarea economică a statului, industria turismului, dar și alte aspecte. Un subiect principal a fost legat de eliminarea voucherelor de vacanță pentru cei care au salarii de peste 8000 de lei. Această retragere nu a fost văzută cu ochi buni inclusiv din HoReCa. \"Aici lucrurile sunt discutabile din perspectiva valorii până la care ajung aceste vouchere de vacanță. În principal, discutăm de suma de 8000 de lei net. Este o sumă considerabilă. Majoritatea celor care beneficiau de aceste vouchere de vacanță chiar aveau nevoie pentru că aveau venituri mai mici. Pentru România, pentru felul în care arată sistemul bugetar, cred că 8000 de lei net este o sumă cuprinzătoare. Voucherele de vacanță, într-adevăr, au avut un rol benefic în România. Concediul este refacerea capacității de muncă. Este și în interesul angajatorului să putem să mergem în concediu, astfel încât să putem să fim în continuare prezenți la locul de muncă, cu productivitate. Un avantaj a fost că oamenii cu venituri mai mici și-au putut permite să-și facă concedii în România. Erau niște statistici mai vechi care spuneau că 40% dintre români nu fac concediu, din varii motive. Unul principal era legat de veniturile pe care le au. Am mai avut un avantaj. A crescut foarte tare numărul clasificărilor pe care ministerul nostru îl face. Adică, o stea, două stele, trei stele sau margarete pentru pensiuni. Clasificare însemnând certificarea unui standard de calitate pe care îl primește turistul atunci când merge într-o unitate hotelieră, într-o cazare. Atunci, au venit din ce în ce mai mulți proprietari de hotel, de pensiuni, să se înregistreze. Acesta este un lucru bun, pentru că am reușit să extragem din economia neagră și gri către economia albă din ce în ce mai multe unități de cazare. Încercăm să facem lucrul acesta cu diverse clasificări, inclusiv pe partea de airbnb. Am avut această discuție de foarte multe ori. A fost un efort foarte mare, dar cred că se vor lua din nou în calcul\". VEZI TOATĂ EMISIUNEA AICI:  Fiți la curent cu ultimele noutăți. Urmăriți DCNews și pe Google News'\n",
      " 'Fiecare părinte de copii mici s-a confruntat cu izbucniri de furie și frustrare din partea celor mici, fie că este timpul să se trezească, să meargă la culcare sau să mănânce un sandviș fără margini tăiate. Potrivit unui nou studiu, există însă și un alt motiv posibil pentru frecvența izbucnirilor celor mici: utilizarea tabletelor.  Noul studiu, publicat în revista JAMA Pediatrics și citat de CNN, arată că utilizarea tabletelor de către copii la vârsta de 3,5 ani a fost asociată cu un număr mai mare de manifestări de furie și frustrare un an mai târziu. În plus, copiii care erau mai predispuși la furie și frustrare la vârsta de 4,5 ani erau mai susceptibili de a avea o utilizare mai mare a tabletelor un an mai târziu (la vârsta de 5,5 ani). Utilizarea tabletelor în copilăria timpurie „poate contribui la un ciclu” de probleme în reglarea emoțională, au scris autorii. Am vrut să obțin mai mult context cu privire la acest lucru vorbind cu expertul în wellness CNN Dr. Leana Wen. Wen este medic de urgență și profesor asociat adjunct la Universitatea George Washington și a fost anterior comisarul pentru sănătate din Baltimore. La fel de important, ea este mama a doi copii mici. „Acest studiu a fost un sondaj realizat pe 315 părinți ai unor copii de vârstă preșcolară din Nova Scotia, Canada. Aceiași părinți au luat parte la studiu când copiii lor aveau 3,5 ani (în 2020), 4,5 ani (în 2021) și 5,5 ani (2022). Aceștia au raportat singuri utilizarea tabletelor de către copiii lor și apoi au evaluat exprimarea furiei copiilor lor folosind un chestionar standard numit Chestionarul de comportament al copiilor.  Cercetătorii au constatat o asociere între utilizarea tabletelor la vârsta de 3,5 ani și o creștere a furiei și frustrării la vârsta de 4,5 ani. Ei au observat că asocierea dintre utilizarea tabletelor și furie a fost bidirecțională, deoarece copiii ai căror părinți au observat un nivel mai ridicat de furie și frustrare la 4,5 ani aveau, de asemenea, o utilizare mai mare a tabletelor la 5,5 ani. Aceasta înseamnă că efectele ar putea merge în ambele sensuri. Asocierea bidirecțională dintre utilizarea tabletelor și exprimarea furiei și frustrării a fost semnificativă și ar trebui să fie un avertisment pentru părinți să fie atenți la timpul petrecut în fața ecranului.”, a explicat Dr. Leana Wen. O lucrare publicată chiar anul acesta clarifică de ce utilizarea tabletelor ar putea fi legată de accesele de furie. Cercetătorii au descoperit că, în rândul copiilor cu vârste cuprinse între 2 și 5 ani, cei ai căror părinți foloseau adesea tehnologia pentru a-și gestiona emoțiile negative aveau mai multe șanse de a prezenta o gestionare deficitară a furiei și frustrării un an mai târziu. De asemenea, acești copii erau mai puțin capabili să decidă asupra unui răspuns deliberat în locul unei reacții automate. Unul dintre motive este acela că copiii trebuie să învețe să își gestioneze singuri emoțiile negative. Ei trebuie să treacă prin acest proces ca parte a dezvoltării lor în copilărie, ajutați de părinți, îngrijitori și profesori. Dacă, în schimb, li se dă o tabletă, un computer sau un smartphone în încercarea de a-i liniști, ei nu vor învăța să gestioneze singuri aceste emoții. Acest lucru ar putea duce la probleme mai târziu în copilărie și la vârsta adultă, inclusiv cu gestionarea furiei.  „Cred că noul studiu JAMA Pediatrics, precum și alte cercetări, ilustrează faptul că tabletele, smartphone-urile și alte dispozitive electronice nu ar trebui să fie folosite ca suzete. Nu ar trebui să fie date copiilor atunci când plâng și sunt supărați pentru a încerca să îi calmeze. De asemenea, nu ar trebui să fie folosite ca o bonă care ia locul unui adult care interacționează cu copilul. Copiii învață prin implicarea socială activă cu ceilalți, iar o mare problemă a ecranelor - fie că este vorba de jocuri cu aplicații sau de vizionarea de filme sau emisiuni TV - este că acestea înlocuiesc interacțiunea față în față cu alți copii și adulți.”, a mai explicat expertul citat de CNN.      Fiecare părinte de copii mici s-a confruntat cu izbucniri de furie și frustrare din partea celor mici, fie că este timpul să se trezească, să meargă la culcare sau să mănânce un sandviș fără margini tăiate. Potrivit unui nou studiu, există însă și un alt motiv posibil pentru frecvența izbucnirilor celor mici: utilizarea tabletelor.   Noul studiu, publicat în revista JAMA Pediatrics și citat de CNN, arată că utilizarea tabletelor de către copii la vârsta de 3,5 ani a fost asociată cu un număr mai mare de manifestări de furie și frustrare un an mai târziu. În plus, copiii care erau mai predispuși la furie și frustrare la vârsta de 4,5 ani erau mai susceptibili de a avea o utilizare mai mare a tabletelor un an mai târziu (la vârsta de 5,5 ani). Utilizarea tabletelor în copilăria timpurie „poate contribui la un ciclu” de probleme în reglarea emoțională, au scris autorii. Am vrut să obțin mai mult context cu privire la acest lucru vorbind cu expertul în wellness CNN Dr. Leana Wen. Wen este medic de urgență și profesor asociat adjunct la Universitatea George Washington și a fost anterior comisarul pentru sănătate din Baltimore. La fel de important, ea este mama a doi copii mici.  Citește și   Recomandare din top articole  Un chirurg pediatru, care costumează copiii bolnavi în supereroi înainte de a-i aduce în sala de operații, a ajuns viral pe TikTok   „Acest studiu a fost un sondaj realizat pe 315 părinți ai unor copii de vârstă preșcolară din Nova Scotia, Canada. Aceiași părinți au luat parte la studiu când copiii lor aveau 3,5 ani (în 2020), 4,5 ani (în 2021) și 5,5 ani (2022). Aceștia au raportat singuri utilizarea tabletelor de către copiii lor și apoi au evaluat exprimarea furiei copiilor lor folosind un chestionar standard numit Chestionarul de comportament al copiilor.         Cercetătorii au constatat o asociere între utilizarea tabletelor la vârsta de 3,5 ani și o creștere a furiei și frustrării la vârsta de 4,5 ani. Ei au observat că asocierea dintre utilizarea tabletelor și furie a fost bidirecțională, deoarece copiii ai căror părinți au observat un nivel mai ridicat de furie și frustrare la 4,5 ani aveau, de asemenea, o utilizare mai mare a tabletelor la 5,5 ani. Aceasta înseamnă că efectele ar putea merge în ambele sensuri. Asocierea bidirecțională dintre utilizarea tabletelor și exprimarea furiei și frustrării a fost semnificativă și ar trebui să fie un avertisment pentru părinți să fie atenți la timpul petrecut în fața ecranului.”, a explicat Dr. Leana Wen.  Citește și   Recomandare din top articole  Telefoanele și tabletele pot provoca „leziuni permanente ale creierului”. Medicul Codruț Sarafoleanu: „Copiii sunt cei mai expuşi”   O lucrare publicată chiar anul acesta clarifică de ce utilizarea tabletelor ar putea fi legată de accesele de furie. Cercetătorii au descoperit că, în rândul copiilor cu vârste cuprinse între 2 și 5 ani, cei ai căror părinți foloseau adesea tehnologia pentru a-și gestiona emoțiile negative aveau mai multe șanse de a prezenta o gestionare deficitară a furiei și frustrării un an mai târziu. De asemenea, acești copii erau mai puțin capabili să decidă asupra unui răspuns deliberat în locul unei reacții automate. Unul dintre motive este acela că copiii trebuie să învețe să își gestioneze singuri emoțiile negative. Ei trebuie să treacă prin acest proces ca parte a dezvoltării lor în copilărie, ajutați de părinți, îngrijitori și profesori. Dacă, în schimb, li se dă o tabletă, un computer sau un smartphone în încercarea de a-i liniști, ei nu vor învăța să gestioneze singuri aceste emoții. Acest lucru ar putea duce la probleme mai târziu în copilărie și la vârsta adultă, inclusiv cu gestionarea furiei. „Cred că noul studiu JAMA Pediatrics, precum și alte cercetări, ilustrează faptul că tabletele, smartphone-urile și alte dispozitive electronice nu ar trebui să fie folosite ca suzete. Nu ar trebui să fie date copiilor atunci când plâng și sunt supărați pentru a încerca să îi calmeze. De asemenea, nu ar trebui să fie folosite ca o bonă care ia locul unui adult care interacționează cu copilul. Copiii învață prin implicarea socială activă cu ceilalți, iar o mare problemă a ecranelor - fie că este vorba de jocuri cu aplicații sau de vizionarea de filme sau emisiuni TV - este că acestea înlocuiesc interacțiunea față în față cu alți copii și adulți.”, a mai explicat expertul citat de CNN.'\n",
      " 'O nouă dispariție misterioasă în Grecia. Un nou turist este de negăsit după ce săptămâna trecută un cunoscut prezentator britanic a dispărut de pe insula Symi din Grecia, iar un turist olandez a dispărut zilele trecute de pe insula grecească Samos. De această dată este vorba despre un turist american care a dispărut după ce a plecat singur într-o excursie pe insula Amorgos. Oficialii locali spun că Albert Calibet, în vârstă de 59 de ani, a dispărut marți după-amiază. Prietenul său a raportat că acesta nu s-a mai întors din drumeție, scrie BBC. Mai multe agenții participă la căutarea acestuia, inclusiv voluntari din paza de coastă și echipe din insulele vecine Paros și Naxos, potrivit radiodifuzorului public grec ERT News. Dispariția sa vine la câteva zile după cadavrul prezentatorului de televiziune britanic Michael Mosley a fost găsit pe insula grecească Symi. Acum forțele de ordine îl caută pe turistul dispărut de pe insula Amorgos atât pe uscat, cât și pe apă, într-o zonă care acoperă aproape un sfert din insulă, a declarat primarul insulei, Eleftherios Karaiskos, pentru ERT. Ei au folosit o dronă pentru a căuta în partea de nord a insulei și încearcă, de asemenea, să urmărească cele două telefoane mobile ale lui Calibet. Apelurile către turistul american\\xa0- despre care primarul a spus că a mai vizitat insula - au rămas fără răspuns. Fratele și iubita lui Albert Calibet sunt în drum spre Grecia pentru a ajuta la efortul de căutare, a informat ABC News. Primarul insulei a spus că drumeția în care s-a aventurat turistul american nu a fost deosebit de provocatoare, ceea ce sugerează că americanul ar fi putut să se abată de la ruta planificată. Albert Calibet, descris ca un ofițer de poliție pensionat din județul Los Angeles, a început o excursie marți dimineață în satul Aegiali, potrivit presei locale. Câteva minute mai târziu se crede că a trimis un mesaj text cu o poză a semnului care arată traseul pe care îl făcea spre Katapola, aproximativ patru ore de mers pe jos. Aproximativ două ore mai târziu, o localnică a spus că a vorbit cu turistul dispărut după ce acesta a cumpărat băuturi de la un magazin din apropiere. Sofia Liviaki a declarat pentru Mega TV că americanul\\xa0a băut o băutură răcoritoare, i-a arătat traseul planificat și a luat o sticlă de apă cu el pentru tot restul călătoriei. Fiți la curent cu ultimele noutăți. Urmăriți DCNews și pe Google News'\n",
      " 'Şase persoane au murit de insolaţie la Tokyo în ultimele zile, în timp ce Japonia se confruntă cu un rar val de căldură în plin sezon ploios, determinând autorităţile să emită mai multe avertismente sanitare, informează AFP. În weekend, prefectura Shizuoka (centru) a fost prima din Japonia unde mercurul din termometre a atins 40 grade Celsius în acest an, depăşind cu mult pragul de 35 grade Celsius corespunzător definiţiei unei zile \"extrem de calde\" conform autorităţilor meteorologice. O astfel de căldură intensă în timpul sezonului ploios este prematură şi \"destul de rară\", fiind cauzată în parte de un puternic sistem de înaltă presiune din Pacificul de Sud, a declarat pentru AFP un responsabil al agenţiei meteorologice nipone. Temperaturile au atins, de asemenea, maxime care se apropiau de 40 de grade Celsius luni la Tokyo şi la Wakayama (vest), potrivit mass-media locale, scrie Agerpres. Autorităţile au emis avertizări pentru o mare parte din ţară în ultimele zile, îndemnând locuitorii să evite exerciţiile fizice în aer liber şi utilizeze aerul condiţionat în interior. Capitala a înregistrat trei decese provocate de insolaţie sâmbătă şi alte trei luni, când mercurul din termometre s-a apropiat de 35 de grade Celsius la prânz, potrivit biroului de examinare medicală al oraşului. Insolaţia face în mod particular numeroase victime în Japonia, ţara cu cea mai bătrână populaţie din lume după Monaco. Luni, Asociaţia japoneză de medicină a avertizat că numărul deceselor cauzate de epuizarea termică este în creştere, de la câteva sute pe an acum 20 de ani la aproximativ 1.500 în 2022. Editor :  A.P.'\n",
      " 'Decizia Tribunalului vine în urma unui proces deschis de 5 profesori universitari din cadrul universității care au contestat procesul electoral. Prin urmare, Tribunalul Cluj a decis, joi, suspendarea Hotărârii Senatului Universitar al USAMV Cluj-Napoca nr. 850/12.01.2024 cu privire la avizarea candidaturii pentru funcția de rector a prof. dr. Cornel Cătoi și a Hotărârii Senatului Universitar al USAMV Cluj-Napoca nr. 2729/07.02.2024 cu privire la validarea alegerilor pentru funcția de rector. Soluția Tribunalului este executorie. Decizia poate fi atacată cu recurs în termen de 5 zile de la data comunicării. \"Admite în parte cererea de suspendare a executării actelor administrative, formulată în temeiul art. 14 din Legea nr. 554/2004 de reclamanţii M L, O N-A, F V, C R, C D, în contradictoriu cu pârâta U Ş A M V C-N C şi intervenient forţat prof. univ. dr. rector C C. Dispune suspendarea executării Hotărârii nr. 850/12.01.2024 şi Hotărârii nr. 2729/07.02.2024 emise de Senatul Universităţii de Ştiinţe Agricole şi Medicină Veterinară Cluj-Napoca, până la soluţionarea definitivă a acţiunii de fond. Respinge ca neîntemeiată cererea de suspendare a executării Hotărârii nr. 1706/25.01.2024 emisă de Senatul Universităţii de Ştiinţe Agricole şi Medicină Veterinară Cluj-Napoca. Ia act că reclamanţii vor solicita cheltuieli de judecată pe cale separată şi respinge cererea pârâtei şi intervenientului de obligare a reclamanților la plata de cheltuieli de judecată. Cu drept de recurs, în termen de 5 zile de la data comunicării. Cererea de recurs se va depune la Tribunalul Cluj. Pronunţată prin punerea soluţiei la dispoziţia părţilor prin intermediul grefei instanţei azi, 06.06.2024.\", arată soluția instanței. Neregulile sesizate de profesorii reclamanți în cadrul dosarului nr. 1851/117/2024 țintesc două argumente principale, conform avocatului lor Alexandru Valerian Dima: \"Candidatura nelegală a domnului prof. dr. Cornel Cătoi la funcția de rector al USAMV Cluj-Napoca întrucât Legea 199/2023 a învățământului superior interzice unei persoane să ocupe funcția de rector la aceeaşi instituţie de învăţământ superior pentru mai mult de două mandate, iar rectorul suspendat al USAMV Cluj-Napoca în prezent se află la cel de-al treilea mandat. Alegerile pentru funcția de rector al USAMV Cluj-Napoca au fost viciate prin faptul că un număr de 413 studenți au fost excluși de pe listele de votare pentru reprezentanții studenților (Prefectul Studenților, reprezentanții studenților în Consiliile Facultăților, respectiv reprezentanții studenților în Senatul Universitar).\" Fiți la curent cu ultimele noutăți. Urmăriți DCNews și pe Google News'\n",
      " 'Grecia rămâne una dintre destinațiile de vacanță preferate de români, iar frumusețea insulelor sale atrage anual mii de vizitatori. Însă, în timp ce cele mai cunoscute insule se bucură de o popularitate constantă, Delos, deși mai puțin vizitată, oferă o experiență unică datorită valorii sale istorice și arheologice. Considerată locul de naștere al zeului Apollo, insula găzduiește un sit arheologic impresionant, care este deschis pentru vizitatori. Spre deosebire de alte insule turistice, Delos nu oferă posibilități de cazare, neavând hoteluri sau pensiuni. Cei care doresc să viziteze insula pot ajunge aici doar cu feribotul, plecând de pe insulele vecine precum Paros, Naxos sau Mykonos. În ciuda dimensiunilor sale mici, Delos a fost un centru cultural și religios important în Antichitate, atrăgând interesul istoricilor și arheologilor din întreaga lume. În ultimele decenii, Delos a avut foarte puțini locuitori. În anul 2001, pe insulă trăiau doar 14 persoane, iar în 2011 numărul acestora a crescut la 24. Cu toate acestea, insula rămâne un loc izolat, accesibil doar pe mare, fără drumuri care să permită transportul cu mașina. Pe măsură ce insula continuă să se scufunde, cei care vor să descopere Delos trebuie să se grăbească. Vizitarea acestui loc special, încărcat de legende și istorie, este o experiență care ar putea deveni în curând imposibilă.'\n",
      " 'Clipul video cu fapta bărbatului a devenit imediat viral. În timp ce unii internauți îi critică gestul, alții îl felicită spunând că este bine dacă se descurcă.'\n",
      " 'Termometrele vor indica chiar și 40 de grade Celsius în mai bine de jumătate de țară, însă temperatura resimtiță va fi mult mai mare, avertizează meteorologii. Până la sfârşitul săptămânii valul de căldură se va menţine și va crește puternic în mai multe zone. Oamenii se tem și spun că fac tot ce pot să se ferească de căldură. Medicii trag un semnal de alarmă și spun că expunerea îndelungată la soare poate duce la probleme grave de sănătate, inclusiv cancer de piele. \"Sunt mai predispuse persoanele cu pielea deschisă la culoare, cum numim noi - fototip 2 - adica persoanele cu ochii albastrii, ochii verzi, care nu au acel pigment natural de care vorbeam. Este vorba de efectul cumulat al ultravioletelor\", spun medicii.'\n",
      " 'Paul al României a fost arestat preventiv în Malta până pe data de 9 mai, anunță Alina Gorghiu, ministrul Justiției. El a fost reținut duminică într-un resort din acest stat. „Din informațiile pe care le avem, solicitarea acestuia, de a fi eliberat pe cauțiune, a fost respinsă, decizie care poate fi însă contestată. După cum știți, acesta a fost condamnat la pedeapsa de 3 ani şi 4 luni închisoare pentru săvârşirea infracţiunilor de cumpărare de influenţă şi complicitate la abuz în serviciu, în dosarul Ferma Băneasa. Ministerul Justiției va continua demersurile și va depune eforturi pentru ca prințul Paul să-și execute pedeapsa în România, așa cum procedează cu orice fugar al statului român. Vom informa cu privire la etapele procedurale ulterioare. Vom furniza toate documentele și informațiile necesare pentru ca instanța din Malta să accepte predarea fugarului”, a precizat Alina Gorghiu într-o postare pe Facebook. Paul Phillipe al României, unul dintre fugarii celebri de la noi în țară, a fost prins duminică în Malta, unde plecase după ce a fost eliberat pe cauțiune de o instanță din Franța. Era într-un resort, în vacanță, de unde a fost ridicat de polițiști. Era fugit de aproape patru ani din România, unde este condamnat la 3 ani și 4 luni de închisoare. Mandatul european de arestare pe numele lui era încă activ, chiar dacă Franța, în urmă cu trei săptămâni, a decis să refuze extrădarea lui. Polițiștii români au colaborat cu polițiștii din Malta și l-au ridicat chiar din resortul unde era cazat.  Editor :  D.C.'\n",
      " 'Comentariile sale vin după ce secretarul de stat american, Antony Blinken, a declarat că depinde de Hamas să facă progrese suplimentare în ceea ce privește armistițiul. \"Mingea este în terenul lor\", a spus el. \"Lucrăm intens la asta și vom vedea ce vor face\", a adăugat Blinken înainte de o întâlnire cu ministrul turc de externe Hakan Fidan, care va avea loc vineri. El a spus că SUA rămâne \"intens concentrată\" pe asigurarea unei încetări a focului. Hamas a părăsit joi negocierile de la Cairo fără un acord, reducând speranțele că se va ajunge la un acord înainte de începerea lunii sfinte musulmane a Ramadanului - care se preconizează că va începe duminică seara, în funcție de momentul în care va fi observată luna nouă. SUA vizau un armistițiu înainte de începerea Ramadanului. Israelul și Hamas s-au acuzat reciproc pentru lipsa unui acord. Între timp, Pentagonul a negat că parașutările de ajutoare americane au provocat victime civile în Gaza vineri. Oficialii palestinieni au raportat că cinci persoane au fost ucise și alte câteva au fost rănite atunci când cutii cu ajutoare au căzut peste ele din greșeală. Imaginile au arătat zeci de oameni alergând în timp ce cutiile au fost aruncate. \"Rapoartele de presă potrivit cărora parașutările aeriene americane au provocat victime civile la sol sunt false\", a declarat un purtător de cuvânt al Pentagonului. \"Am confirmat că toate pachetele noastre de ajutoare au aterizat în siguranță la sol\", a spus purtătorul de cuvânt. Țări precum SUA, Marea Britanie și Iordania au trimis pachete de ajutoare în Gaza pe calea aerului, în timp ce teritoriul se confruntă cu o catastrofă umanitară din ce în ce mai gravă. Potrivit purtătorului de cuvânt al Pentagonului, forțele americane au parașutat în total 124.000 de mese în Gaza până în prezent. Parașutările aeriene oferă cantități de ajutor considerabil mai mici decât livrările cu camioanele, iar grupurile umanitare au avertizat că a devenit aproape imposibil să livreze provizii în cea mai mare parte a Fașiei Gaza, conform Sky News. Fiți la curent cu ultimele noutăți. Urmăriți DCNews și pe Google News']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "def list_to_numpy_memmap_chunked(large_list, filename, chunk_size=20000):\n",
    "    # Determine the maximum length of the strings in the list\n",
    "    max_len = max(len(str(item)) for item in large_list)\n",
    "    dtype = f'<U{max_len}'  # Update dtype to accommodate the longest string\n",
    "    \n",
    "    # Create a memory-mapped file\n",
    "    memmap_array = np.memmap(filename, dtype=dtype, mode='w+', shape=(len(large_list),))\n",
    "    \n",
    "    # Write data to the memory-mapped file in chunks\n",
    "    for i in tqdm(range(0, len(large_list), chunk_size)):\n",
    "        chunk = large_list[i:i + chunk_size]\n",
    "        memmap_array[i:i + chunk_size] = np.array(chunk, dtype=dtype)\n",
    "    \n",
    "    # Flush changes to disk\n",
    "    memmap_array.flush()\n",
    "    \n",
    "    return memmap_array\n",
    "\n",
    "# Example usage\n",
    "large_list = X_list  # Replace with your actual list\n",
    "filename = 'large_array.dat'\n",
    "X = list_to_numpy_memmap_chunked(large_list, filename)\n",
    "print(X[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 78.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['romana' 'romana' 'romana' 'romana' 'romana' 'romana' 'romana' 'romana'\n",
      " 'romana' 'romana']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "def list_to_numpy_memmap_chunked(large_list, filename, chunk_size=20000):\n",
    "    # Determine the maximum length of the strings in the list\n",
    "    max_len = max(len(str(item)) for item in large_list)\n",
    "    dtype = f'<U{max_len}'  # Update dtype to accommodate the longest string\n",
    "    \n",
    "    # Create a memory-mapped file\n",
    "    memmap_array = np.memmap(filename, dtype=dtype, mode='w+', shape=(len(large_list),))\n",
    "    \n",
    "    # Write data to the memory-mapped file in chunks\n",
    "    for i in tqdm(range(0, len(large_list), chunk_size)):\n",
    "        chunk = large_list[i:i + chunk_size]\n",
    "        memmap_array[i:i + chunk_size] = np.array(chunk, dtype=dtype)\n",
    "    \n",
    "    # Flush changes to disk\n",
    "    memmap_array.flush()\n",
    "    \n",
    "    return memmap_array\n",
    "\n",
    "# Example usage\n",
    "large_list = y_list  # Replace with your actual list\n",
    "filename = 'large_array_y.dat'\n",
    "y = list_to_numpy_memmap_chunked(large_list, filename)\n",
    "print(y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.1, random_state=11)\n",
    "text_clf = Pipeline(steps=[\n",
    "        ('tfidf', TfidfVectorizer(min_df=3, max_df=0.7, max_features=10000, vocabulary=stop_words)),\n",
    "        ('clf', LogisticRegression(penalty='l2'))\n",
    "    ], verbose=True)\n",
    "parameters = {\n",
    "    'tfidf__ngram_range': [(1, 1), (2, 2), (3, 3), (4, 4)],\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'clf__C': (0.1, 1, 10),\n",
    "}\n",
    "gs_clf = GridSearchCV(text_clf, parameters, cv=sss, n_jobs=-1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1 out of 5\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "gs_scores = []\n",
    "\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    # Print split x out of y\n",
    "    print(f\"Split {len(scores) + 1} out of {sss.get_n_splits()}\")\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]   \n",
    "    \n",
    "    text_clf = text_clf.fit(X_train, y_train)\n",
    "    scores.append(text_clf.score(X_test, y_test))\n",
    "    \n",
    "    gs_clf = gs_clf.fit(X_train, y_train)\n",
    "    gs_scores.append(gs_clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 9121/45685 [24:24<1:37:52,  6.23it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m y_train, y_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([]), np\u001b[38;5;241m.\u001b[39marray([])\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ti \u001b[38;5;129;01min\u001b[39;00m tqdm(train_index): \n\u001b[0;32m---> 10\u001b[0m     X_train \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mti\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     y_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mappend(y_train, y[ti])\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ti \u001b[38;5;129;01min\u001b[39;00m tqdm(test_index):\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/numpy/lib/function_base.py:5618\u001b[0m, in \u001b[0;36mappend\u001b[0;34m(arr, values, axis)\u001b[0m\n\u001b[1;32m   5616\u001b[0m     values \u001b[38;5;241m=\u001b[39m ravel(values)\n\u001b[1;32m   5617\u001b[0m     axis \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mndim\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 5618\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "scores = []\n",
    "gs_scores = []\n",
    "\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    X_train, X_test = np.array([]), np.array([])\n",
    "    y_train, y_test = np.array([]), np.array([])\n",
    "    for ti in tqdm(train_index): \n",
    "        X_train = np.append(X_train, X[ti])\n",
    "        y_train = np.append(y_train, y[ti])\n",
    "    for ti in tqdm(test_index):\n",
    "        X_test = np.append(X_test, X[ti])\n",
    "        y_test = np.append(y_test, y[ti])\n",
    "    \n",
    "    text_clf = text_clf.fit(X_train, y_train)\n",
    "    scores.append(text_clf.score(X_test, y_test))\n",
    "    \n",
    "    gs_clf = gs_clf.fit(X_train, y_train)\n",
    "    gs_scores.append(gs_clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score:  0.9980392156862745\n",
      "Mean grid search score:  0.9980392156862745\n",
      "Best parameters:  {'clf__C': 1, 'tfidf__ngram_range': (1, 1), 'tfidf__use_idf': True}\n",
      "Best score:  0.9989130434782609\n",
      "Classification report:                precision    recall  f1-score   support\n",
      "\n",
      "     moldova       0.99      1.00      1.00       102\n",
      "      romana       1.00      0.99      1.00       102\n",
      "\n",
      "    accuracy                           1.00       204\n",
      "   macro avg       1.00      1.00      1.00       204\n",
      "weighted avg       1.00      1.00      1.00       204\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean score: \", np.mean(scores))\n",
    "print(\"Mean grid search score: \", np.mean(gs_scores))\n",
    "print(\"Best parameters: \", gs_clf.best_params_)\n",
    "print(\"Best score: \", gs_clf.best_score_)\n",
    "print(\"Classification report: \", classification_report(y_test, gs_clf.predict(X_test), ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:  Update 14:36. \"La interventia de la zona de triaj din Gara Basarab, se redimensioneaza dispozitivul, ramin 7 autospeciale de stingere cu apa si spuma. Se lucreaza la stingerea ultimelor 3 vagoane\", transmite ISU B-IF. Update 13:23: La interventia de la zona de triaj din Gara Basarab, an momentul de fata incendiul este localizat. Au fost afectate 15 vagoane dezafectate. Update 12:47: \"Avind in vedere modul de manifestare a incendiului, dispozitivul se suplimenteaza cu 5 cisterne de mare capacitate pentru a realiza rezerva de apa. An total actioneaza 9 autospesciale de stingere cu apa si spuma si 5 cisterne\", precizeaza ISU-B-IF. Reprezentantii ISU Bucuresti-Ilfov au anuntat ca pompierii intervin pentru stingerea unui incendiu produs la doua vagoane dezafectate, an zona de triaj dintre Gara Basarab si Podul Grant. An GALERIA FOTO puteti gasi imagini din timpul interventiei pompierilor         ››› Vezi galeria foto ‹‹‹ \"Intervenim pentru stingerea unui incendiu produs la doua vagoane dezafectate, in zona de triaj dintre Gara Basarab si Podul Grant. Au fost alertate 7 autospeciale de stingere cu apa si spuma, o autospeciala de descarcerare si o ambulanta SMURD. Incendiul se manifesta cu flacara deschisa si degajari mari de fum. Misiunea este an dinamica, revenim cu date\", informeaza ISU B-IF.   \"Avind an vedere modul de manifestare a incendiului, care prezinta posibilitate de extindere si la alte vagoane, dispozitivul se suplimenteaza cu 2 autospeciale de stingere\", transmite ISU B-IF. \"A fost emis un mesaj prin sistemul RO-Alert\" \"Avind an vedere degajarea intensa de fum, pentru avertizarea si informarea populatiei a fost emis un mesaj prin sistemul RoAlert\", se arata antr-o informare a autoritatilor.\n",
      "Real:  romana\n",
      "Predicted:  moldova\n",
      "Index of the text:  (array([33]),)  Out of  204\n",
      "Text:  Chiar si pentru punctele negre este de ajutor. Coaja de portocala uscata la soare si maruntita apoi pentru a obtine o pulbere, oate fi folosita pentru un peeling bogat in vitamina C. De asemenea, un scrub pentru corp este eficient. Amestecat cu iaurt, poate oferi o stralucire si reducerea petelor de pe piele, scrie Cc-juice.ro, Portocala este eficienta si pentru tratarea cosurilor formate prin blocarea porilor cu praf. Feliile de portocale contin o cantitate mare de fibre dietetice, care regleaza miscarile intestinului, eliminand astfel toxinele din organism. Acest lucru va impiedica aparitia acneei prin eliminarea toxinelor.Pe de alta parte, coaja de portocale este un agent natural de albire care poate elimina in mod eficient petele pigmentare de pe piele.Fiind o sursa bogata de vitamina C, portocalele au efect anti-imbatranire. De asemenea, ajuta la restabilira colagenului din organism, care este responsabil pentru fermitatea pielii si previne imbatranirea prematura a acesteia.Uleiurile din coaja de portocala sunt potrivite atat pentru tenul gras, cat si pentru cel uscat. Aplicarea cojilor de portocala pe piele elimina celulele moarte si murdaria, mentinand pielea hidratata si tonifiata.Coaja de portocala poate fi folosita si cruda. Pur si simplu toarna apa fierbinte peste coaja de portocala macinata si las-o o zi la macerat. Apoi fultreaza lichidul si aplica-l pe fata cu o discheta de bumbac.\n",
      "Real:  moldova\n",
      "Predicted:  romana\n",
      "Index of the text:  (array([42]),)  Out of  204\n",
      "Text:  Politic UPDATE 11:00 Cabinetul de Ministri a adoptat hotararea privind reorganizarea Universitatea de Stat din Moldova prin fuziunea (absorbtia) Universitatii de Stat de Educatie Fizica si Sport.De asemenea, membrii Guvernului urmeaza sa examineze modificarile la Legea privind asigurarea activitatii presedintelui Republicii Moldova. Potrivit proiectului de hotarare, modificarile tin de modul de acordare a pensiei.\n",
      "Real:  moldova\n",
      "Predicted:  romana\n",
      "Index of the text:  (array([43]),)  Out of  204\n",
      "Text:  Aderare UE Premierul Marcel Ciolacu a salutat decizia Consiliului European si a transmis felicitari Republicii Moldova si Ucrainei pentru demararea negocierilor de aderare la UE, subliniind ca Romania ramane un sustinator ferm pe tot parcursul procesului de negocieri, scrie Agerpres.I welcome the @EUCouncil decision and congratulate the Republic of Moldova & Ukraine for the starting of the #EU accession negotiations.Romania is and will continue to be a steadfast supporter throughout the negotiation process.,,Salut decizia Consiliului UE si felicit Republica Moldova si Ucraina pentru demararea negocierilor de aderare la UE. Romania este si va continua sa fie un sustinator ferm pe tot parcursul procesului de negocieri\", a transmis Marcel Ciolacu, intr-o postare pe pagina sa de X.Mentionam ca joi, 14 decembrie, Consiliul European a decis lansarea negocierilor de aderare cu Ucraina si Republica Moldova. Anuntul a fost facut de catre presedintele Consiliului European, Charles Michel.\n",
      "Real:  moldova\n",
      "Predicted:  romana\n",
      "Index of the text:  (array([102]),)  Out of  204\n",
      "Text:   Traversarea camioanelor prin postul vamal Leuseni-Albita este restrictionata. La aceasta ora, partea romana interzice temporar circulatia camioanelor din cauza ninsorii si poleiului pe drumurile publice, anunta Politia de Frontiera.,,Pentru alte tipuri de mijloace de transport se permite trecerea frontierei, solicitam sa fie echipate corespunzator!\", precizeaza Politia de Frontiera. Din cauza vantului puternic, starea drumurilor si nemijlocit situatia pe traseele nationale si internationale se poate schimba brusc. Pentru siguranta transportatorilor, Politia de Frontiera recomanda evitarea pornirii la drum. Politia de Frontiera Din cauza vantului puternic, starea drumurilor si nemijlocit situatia pe traseele nationale si internationale se poate schimba brusc. Pentru siguranta transportatorilor, Politia de Frontiera recomanda evitarea pornirii la drum. Politia de Frontiera Politia de Frontiera\n",
      "Real:  moldova\n",
      "Predicted:  romana\n",
      "Index of the text:  (array([163]),)  Out of  204\n"
     ]
    }
   ],
   "source": [
    "missclassified = []\n",
    "for i in range(len(y_test)):\n",
    "    if y_test[i] != gs_clf.predict(X_test)[i]:\n",
    "        missclassified.append((X_test[i], y_test[i], gs_clf.predict(X_test)[i]))\n",
    "        if len(missclassified) == 5:\n",
    "            break\n",
    "        \n",
    "for text, real, predicted in missclassified:\n",
    "    print(\"Text: \", text)\n",
    "    print(\"Real: \", real)\n",
    "    print(\"Predicted: \", predicted)\n",
    "    print(\"Index of the text: \", np.where(X_test == text), \" Out of \", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real:  moldova  Predicted:  moldova  Probability:  [0.99544689 0.00455311]\n",
      "Real:  moldova  Predicted:  moldova  Probability:  [9.99967272e-01 3.27281458e-05]\n",
      "Real:  romana  Predicted:  romana  Probability:  [0.02135334 0.97864666]\n",
      "Real:  romana  Predicted:  romana  Probability:  [0.00709559 0.99290441]\n",
      "Real:  romana  Predicted:  romana  Probability:  [0.02806754 0.97193246]\n",
      "Real:  romana  Predicted:  romana  Probability:  [0.03888786 0.96111214]\n",
      "Real:  moldova  Predicted:  moldova  Probability:  [0.9940769 0.0059231]\n",
      "Real:  moldova  Predicted:  moldova  Probability:  [9.99967612e-01 3.23876247e-05]\n",
      "Real:  moldova  Predicted:  moldova  Probability:  [9.99370151e-01 6.29848830e-04]\n",
      "Real:  romana  Predicted:  romana  Probability:  [0.10092349 0.89907651]\n",
      "Real:  moldova  Predicted:  moldova  Probability:  [9.99995264e-01 4.73612281e-06]\n",
      "Real:  moldova  Predicted:  moldova  Probability:  [9.99976670e-01 2.33304056e-05]\n",
      "Real:  romana  Predicted:  romana  Probability:  [0.01728282 0.98271718]\n",
      "Real:  romana  Predicted:  romana  Probability:  [0.02780692 0.97219308]\n",
      "Real:  romana  Predicted:  romana  Probability:  [0.00571484 0.99428516]\n",
      "Real:  moldova  Predicted:  moldova  Probability:  [9.99596450e-01 4.03549848e-04]\n",
      "Real:  romana  Predicted:  romana  Probability:  [0.02069945 0.97930055]\n",
      "Real:  moldova  Predicted:  moldova  Probability:  [9.99967436e-01 3.25637301e-05]\n",
      "Real:  romana  Predicted:  romana  Probability:  [0.0100502 0.9899498]\n",
      "Real:  moldova  Predicted:  moldova  Probability:  [9.99999665e-01 3.35400836e-07]\n",
      "Real:  romana  Predicted:  romana  Probability:  [0.06874866 0.93125134]\n",
      "Real:  moldova  Predicted:  moldova  Probability:  [9.99930452e-01 6.95482302e-05]\n",
      "Real:  romana  Predicted:  romana  Probability:  [0.01141875 0.98858125]\n",
      "Real:  romana  Predicted:  romana  Probability:  [0.01063396 0.98936604]\n",
      "Real:  moldova  Predicted:  moldova  Probability:  [0.99704769 0.00295231]\n",
      "Real:  moldova  Predicted:  moldova  Probability:  [0.99371934 0.00628066]\n",
      "Real:  moldova  Predicted:  moldova  Probability:  [0.99022772 0.00977228]\n",
      "Real:  moldova  Predicted:  moldova  Probability:  [9.99910442e-01 8.95580850e-05]\n",
      "Real:  moldova  Predicted:  moldova  Probability:  [9.99649079e-01 3.50921487e-04]\n",
      "Real:  romana  Predicted:  romana  Probability:  [0.05499323 0.94500677]\n",
      "Real:  romana  Predicted:  romana  Probability:  [0.00601466 0.99398534]\n",
      "Real:  moldova  Predicted:  moldova  Probability:  [0.93934953 0.06065047]\n",
      "Real:  romana  Predicted:  romana  Probability:  [0.00820982 0.99179018]\n",
      "Real:  romana  Predicted:  moldova  Probability:  [0.65605053 0.34394947]\n",
      "_____________________\n",
      "Real:  romana  Predicted:  romana  Probability:  [0.00597941 0.99402059]\n",
      "Real:  romana  Predicted:  romana  Probability:  [0.02444491 0.97555509]\n",
      "Real:  romana  Predicted:  romana  Probability:  [0.09465511 0.90534489]\n",
      "Real:  moldova  Predicted:  moldova  Probability:  [9.99981233e-01 1.87669246e-05]\n",
      "Real:  moldova  Predicted:  moldova  Probability:  [0.99849754 0.00150246]\n",
      "Real:  moldova  Predicted:  moldova  Probability:  [9.99807590e-01 1.92410152e-04]\n",
      "Real:  romana  Predicted:  romana  Probability:  [0.00522936 0.99477064]\n",
      "Real:  moldova  Predicted:  moldova  Probability:  [0.99721817 0.00278183]\n",
      "Real:  moldova  Predicted:  romana  Probability:  [0.39055278 0.60944722]\n",
      "_____________________\n",
      "Real:  moldova  Predicted:  romana  Probability:  [0.25499164 0.74500836]\n",
      "_____________________\n",
      "Real:  romana  Predicted:  romana  Probability:  [0.00133025 0.99866975]\n",
      "Real:  romana  Predicted:  romana  Probability:  [0.03092619 0.96907381]\n",
      "Real:  moldova  Predicted:  moldova  Probability:  [0.98975234 0.01024766]\n",
      "Real:  moldova  Predicted:  moldova  Probability:  [0.94146393 0.05853607]\n",
      "Real:  moldova  Predicted:  moldova  Probability:  [9.99923478e-01 7.65221628e-05]\n",
      "Real:  moldova  Predicted:  moldova  Probability:  [9.99439020e-01 5.60980203e-04]\n",
      "Real:  romana  Predicted:  romana  Probability:  [0.01536229 0.98463771]\n",
      "Real:  romana  Predicted:  romana  Probability:  [0.00343451 0.99656549]\n",
      "Real:  romana  Predicted:  romana  Probability:  [0.01006106 0.98993894]\n",
      "Real:  moldova  Predicted:  moldova  Probability:  [0.81154004 0.18845996]\n",
      "Real:  romana  Predicted:  romana  Probability:  [0.18214387 0.81785613]\n",
      "Real:  moldova  Predicted:  moldova  Probability:  [9.99992214e-01 7.78614670e-06]\n",
      "Real:  moldova  Predicted:  moldova  Probability:  [9.99760264e-01 2.39736264e-04]\n",
      "Real:  moldova  Predicted:  moldova  Probability:  [9.99540537e-01 4.59463222e-04]\n",
      "Real:  moldova  Predicted:  moldova  Probability:  [9.99998832e-01 1.16805214e-06]\n",
      "Real:  moldova  Predicted:  moldova  Probability:  [0.99314274 0.00685726]\n",
      "Real:  moldova  Predicted:  moldova  Probability:  [9.99228327e-01 7.71673299e-04]\n",
      "Real:  romana  Predicted:  romana  Probability:  [0.00500011 0.99499989]\n",
      "Real:  romana  Predicted:  romana  Probability:  [0.00727117 0.99272883]\n",
      "Real:  romana  Predicted:  romana  Probability:  [0.00520603 0.99479397]\n",
      "Real:  romana  Predicted:  romana  Probability:  [0.02274438 0.97725562]\n",
      "Real:  moldova  Predicted:  moldova  Probability:  [0.99658028 0.00341972]\n",
      "Real:  moldova  Predicted:  moldova  Probability:  [9.99755667e-01 2.44333321e-04]\n",
      "Real:  romana  Predicted:  romana  Probability:  [0.00244104 0.99755896]\n",
      "Real:  romana  Predicted:  romana  Probability:  [0.01686754 0.98313246]\n",
      "Real:  romana  Predicted:  romana  Probability:  [0.03360116 0.96639884]\n",
      "Real:  moldova  Predicted:  moldova  Probability:  [9.99981933e-01 1.80672288e-05]\n",
      "Real:  romana  Predicted:  romana  Probability:  [0.00535303 0.99464697]\n",
      "Real:  romana  Predicted:  romana  Probability:  [0.00353386 0.99646614]\n",
      "Real:  moldova  Predicted:  moldova  Probability:  [9.99999874e-01 1.26340802e-07]\n",
      "Real:  moldova  Predicted:  moldova  Probability:  [9.99960423e-01 3.95770313e-05]\n",
      "Real:  moldova  Predicted:  moldova  Probability:  [0.99760799 0.00239201]\n",
      "Real:  romana  Predicted:  romana  Probability:  [0.03439245 0.96560755]\n",
      "Real:  romana  Predicted:  romana  Probability:  [0.01232181 0.98767819]\n",
      "Real:  romana  Predicted:  romana  Probability:  [0.02868563 0.97131437]\n",
      "Real:  romana  Predicted:  romana  Probability:  [0.00938087 0.99061913]\n",
      "Real:  moldova  Predicted:  moldova  Probability:  [0.99519408 0.00480592]\n",
      "Real:  romana  Predicted:  romana  Probability:  [0.02364224 0.97635776]\n",
      "Real:  moldova  Predicted:  moldova  Probability:  [9.99998501e-01 1.49927349e-06]\n",
      "Real:  romana  Predicted:  romana  Probability:  [0.02278339 0.97721661]\n",
      "Real:  romana  Predicted:  romana  Probability:  [0.26102206 0.73897794]\n",
      "Real:  moldova  Predicted:  moldova  Probability:  [0.99892919 0.00107081]\n",
      "Real:  moldova  Predicted:  moldova  Probability:  [0.99789059 0.00210941]\n",
      "Real:  romana  Predicted:  romana  Probability:  [0.0106486 0.9893514]\n",
      "Real:  romana  Predicted:  romana  Probability:  [0.05386414 0.94613586]\n",
      "Real:  romana  Predicted:  romana  Probability:  [0.03761126 0.96238874]\n",
      "Real:  moldova  Predicted:  moldova  Probability:  [9.99818992e-01 1.81007830e-04]\n",
      "Real:  moldova  Predicted:  moldova  Probability:  [0.89758005 0.10241995]\n",
      "Real:  moldova  Predicted:  moldova  Probability:  [0.91338494 0.08661506]\n",
      "Real:  romana  Predicted:  romana  Probability:  [0.01709281 0.98290719]\n",
      "Real:  romana  Predicted:  romana  Probability:  [0.00574955 0.99425045]\n",
      "Real:  moldova  Predicted:  moldova  Probability:  [0.9628231 0.0371769]\n",
      "Real:  romana  Predicted:  romana  Probability:  [0.06206507 0.93793493]\n",
      "Real:  romana  Predicted:  romana  Probability:  [0.00972071 0.99027929]\n",
      "Real:  moldova  Predicted:  moldova  Probability:  [9.99833061e-01 1.66938945e-04]\n",
      "Real:  romana  Predicted:  romana  Probability:  [0.0023343 0.9976657]\n"
     ]
    }
   ],
   "source": [
    "# Predict first 10 elements of the test set\n",
    "for i in range(len(y_test[:100])):\n",
    "    prediction = gs_clf.predict([X_test[i]])[0]\n",
    "    print(\"Real: \", y_test[i], \" Predicted: \", prediction, \" Probability: \", gs_clf.predict_proba([X_test[i]])[0])\n",
    "    if y_test[i] != prediction:\n",
    "        print(\"_____________________\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=  10.7s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=  10.7s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=  12.8s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=  12.8s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=  13.3s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=  13.3s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=  13.4s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=  13.4s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=  13.3s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=  13.8s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=  14.6s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=  15.2s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=  15.6s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=  16.1s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=  16.5s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=  16.7s\n",
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=  17.6s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 52\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Perform grid search\u001b[39;00m\n\u001b[1;32m     51\u001b[0m gs_clf \u001b[38;5;241m=\u001b[39m GridSearchCV(text_clf, parameters, cv\u001b[38;5;241m=\u001b[39msss, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 52\u001b[0m \u001b[43mgs_clf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_list\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Use raw text data for fitting\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest parameters found: \u001b[39m\u001b[38;5;124m\"\u001b[39m, gs_clf\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/sklearn/model_selection/_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    966\u001b[0m     )\n\u001b[1;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 970\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1527\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1526\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1527\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/sklearn/model_selection/_search.py:916\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    909\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    912\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    913\u001b[0m         )\n\u001b[1;32m    914\u001b[0m     )\n\u001b[0;32m--> 916\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    937\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    938\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    939\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/joblib/parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[1;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/joblib/parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/joblib/parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1702\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1703\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1705\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1706\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1707\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1708\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1710\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1711\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1712\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedShuffleSplit, train_test_split\n",
    "from skorch import NeuralNetClassifier\n",
    "\n",
    "# Assuming stop_words and sss are defined elsewhere in your code\n",
    "\n",
    "# Define a custom logistic regression model\n",
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, 1)  # Output is 1 for binary classification\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.linear(x))\n",
    "\n",
    "# Define the skorch wrapper\n",
    "net = NeuralNetClassifier(\n",
    "    LogisticRegressionModel,\n",
    "    module__input_dim=1000,  # This should match the number of features from TfidfVectorizer\n",
    "    max_epochs=10,\n",
    "    lr=0.1,\n",
    "    optimizer=optim.Adam,\n",
    "    criterion=nn.BCELoss,\n",
    "    verbose=1,\n",
    "    device='cuda'  # Use 'cuda' for GPU\n",
    ")\n",
    "\n",
    "# Define the StratifiedShuffleSplit\n",
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.1, random_state=11)\n",
    "\n",
    "# Define the pipeline\n",
    "text_clf = Pipeline(steps=[\n",
    "    ('tfidf', TfidfVectorizer(min_df=3, max_df=0.7, max_features=1000, vocabulary=stop_words)),\n",
    "    ('clf', net)\n",
    "], verbose=True)\n",
    "\n",
    "# Define the parameter grid\n",
    "parameters = {\n",
    "    'tfidf__ngram_range': [(1, 1), (2, 2), (3, 3), (4, 4)],\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'clf__lr': [0.01, 0.1, 0.2],\n",
    "    'clf__max_epochs': [10, 20],\n",
    "}\n",
    "\n",
    "# Perform grid search\n",
    "gs_clf = GridSearchCV(text_clf, parameters, cv=sss, n_jobs=-1, verbose=1)\n",
    "gs_clf.fit(X_list, y_list)  # Use raw text data for fitting\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Best parameters found: \", gs_clf.best_params_)\n",
    "print(\"Best cross-validation score: \", gs_clf.best_score_)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = gs_clf.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
